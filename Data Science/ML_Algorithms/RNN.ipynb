{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Author: Jacob McCabe\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will take a look at the Recurrent Neural Networks (RNNs). The main ideas covered will include:\n",
    "\n",
    "1. What is a RNN?\n",
    "\n",
    "\n",
    "## What is a RNN?\n",
    "\n",
    "The benefit of a RNN is that it can process sequential data, often this is text. If we tried training a basic neural network on text data, it would treat the text as a bag of words. There would be no memory of word order and no concept of context. A RNN addresses this shortcoming. RNNs would take the first word and use a probabilistic model to predict the next word. That predicted word then is used for predicting the next word. This means that the model can consider the entire sentence to build context for the sequence.\n",
    "\n",
    "## Example using the `Keras` module from `Scikit-learn` \n",
    "\n",
    "A general outline for the example is as follows:\n",
    "\n",
    "- Preparing the data\n",
    "- Creating features and targets\n",
    "- Build the model: embedding, LSTM, and Dense Layers\n",
    "- Load in embeddings\n",
    "- Train the model\n",
    "- Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
